{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Speech Generation for Shakespeare Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/The-Comedy-of-Errors.txt\"\n",
    "\n",
    "with open(fname) as f: \n",
    "    play = f.read()\n",
    "\n",
    "#print(play)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": true,\n",
      "    \"completion\": false,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1679356800,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1742515200\n",
      "  },\n",
      "  \"id\": \"gpt-4-32k\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1679356800\n",
      "}\n",
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": true,\n",
      "    \"completion\": false,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1679356800,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1742515200\n",
      "  },\n",
      "  \"id\": \"gpt-4\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1679356800\n",
      "}\n",
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": false,\n",
      "    \"completion\": true,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1664496000,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1727654400\n",
      "  },\n",
      "  \"id\": \"text-davinci-003\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1664496000\n",
      "}\n",
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": true,\n",
      "    \"completion\": true,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1678320000,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1690848000\n",
      "  },\n",
      "  \"id\": \"gpt-35-turbo\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1678320000\n",
      "}\n",
      "Found a succeeded deployment of \"gpt-4-32k\" that supports text chat_completion with id: gpt-4-32k.\n"
     ]
    }
   ],
   "source": [
    "# id of desired_model\n",
    "desired_model = 'gpt-4-32k' \n",
    "desired_capability = 'chat_completion' # apply as completion, since gpt-4 is only released as chat in Azure OpenAI\n",
    "\n",
    "# list models deployed with\n",
    "deployment_id = None\n",
    "result = openai.Deployment.list()\n",
    "\n",
    "for deployment in result.data:\n",
    "    if deployment[\"status\"] != \"succeeded\":\n",
    "        continue\n",
    "    \n",
    "    model = openai.Model.retrieve(deployment[\"model\"])\n",
    "    print(model)\n",
    "    # check if desired_model is deployed, and if it has 'completion' capability\n",
    "    if model[\"id\"] == desired_model and model['capabilities'][desired_capability]:\n",
    "        deployment_id = deployment[\"id\"]\n",
    "        \n",
    "# if no model deployed, deploy one\n",
    "if not deployment_id:\n",
    "    print('No deployment with status: succeeded found.')\n",
    "\n",
    "    # Deploy the model\n",
    "    print(f'Creating a new deployment with model: {desired_model}')\n",
    "    result = openai.Deployment.create(model=desired_model, scale_settings={\"scale_type\":\"standard\"})\n",
    "    deployment_id = result[\"id\"]\n",
    "    print(f'Successfully created {desired_model} that supports text {desired_capability} with id: {deployment_id}.')\n",
    "else:\n",
    "    print(f'Found a succeeded deployment of \"{desired_model}\" that supports text {desired_capability} with id: {deployment_id}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Casts, Scenes, Acts, Dialogues, Synopsis with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nExtract synopsis, act, scene, casts and associated dialogues, into json format. \n",
    "\"\"\"\n",
    "print(prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Neural Speech  <<--- Do this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv('SPEECH_KEY'), region=os.getenv('SPEECH_REGION'))\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Text to synthesise \n",
    "text = \"Hey, how are you?\"\n",
    "\n",
    "# Synthesise speech\n",
    "result = speech_synthesizer.speak_text_async(text).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_synthesis_to_mp3_file():\n",
    "    \"\"\"performs speech synthesis to a mp3 file\"\"\"\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('SPEECH_KEY'), region=os.getenv('SPEECH_REGION'))\n",
    "    \n",
    "    # Sets the synthesis output format.\n",
    "    # The full list of supported format can be found here:\n",
    "    # https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-text-to-speech#audio-outputs\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3)\n",
    "    \n",
    "    # Creates a speech synthesizer using file as audio output.\n",
    "    # Replace with your own audio file name.\n",
    "    file_name = \"outputaudio.mp3\"\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=file_name)\n",
    "\n",
    "    # Sets the synthesis voice name.\n",
    "    voice = \"Microsoft Server Speech Text to Speech Voice (en-US, JennyNeural)\"  <--- update this\n",
    "    speech_config.speech_synthesis_voice_name = voice\n",
    "\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)\n",
    "\n",
    "    try:\n",
    "        #text = input()\n",
    "        text = \"Proceed, Solinus, to procure my fall, And by the doom of death end woes and all.\"\n",
    "    except EOFError as e:\n",
    "        print(e)\n",
    "        exit()\n",
    "        \n",
    "    result = speech_synthesizer.speak_text_async(text).get()\n",
    "    # Check result\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}], and the audio was saved to [{}]\".format(text, file_name))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [Proceed, Solinus, to procure my fall, And by the doom of death end woes and all.], and the audio was saved to [outputaudio.mp3]\n"
     ]
    }
   ],
   "source": [
    "speech_synthesis_to_mp3_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
