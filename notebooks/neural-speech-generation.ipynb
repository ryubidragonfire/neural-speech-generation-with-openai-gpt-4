{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Speech Generation for Shakespeare Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/The-Comedy-of-Errors.txt\"\n",
    "\n",
    "with open(fname) as f: \n",
    "    play = f.read()\n",
    "\n",
    "#print(play)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Casts, Scenes, Acts, Dialogues, Synopsis with OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Neural Speech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": true,\n",
      "    \"completion\": false,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1679356800,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1742515200\n",
      "  },\n",
      "  \"id\": \"gpt-4-32k\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1679356800\n",
      "}\n",
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": true,\n",
      "    \"completion\": false,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1679356800,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1742515200\n",
      "  },\n",
      "  \"id\": \"gpt-4\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1679356800\n",
      "}\n",
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": false,\n",
      "    \"completion\": true,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1664496000,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1727654400\n",
      "  },\n",
      "  \"id\": \"text-davinci-003\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1664496000\n",
      "}\n",
      "{\n",
      "  \"capabilities\": {\n",
      "    \"chat_completion\": true,\n",
      "    \"completion\": true,\n",
      "    \"embeddings\": false,\n",
      "    \"fine_tune\": false,\n",
      "    \"inference\": true,\n",
      "    \"scale_types\": [\n",
      "      \"standard\"\n",
      "    ]\n",
      "  },\n",
      "  \"created_at\": 1678320000,\n",
      "  \"deprecation\": {\n",
      "    \"inference\": 1690848000\n",
      "  },\n",
      "  \"id\": \"gpt-35-turbo\",\n",
      "  \"lifecycle_status\": \"preview\",\n",
      "  \"object\": \"model\",\n",
      "  \"status\": \"succeeded\",\n",
      "  \"updated_at\": 1678320000\n",
      "}\n",
      "Found a succeeded deployment of \"gpt-4-32k\" that supports text chat_completion with id: gpt-4-32k.\n"
     ]
    }
   ],
   "source": [
    "# id of desired_model\n",
    "desired_model = 'gpt-4-32k' \n",
    "desired_capability = 'chat_completion' # apply as completion, since gpt-4 is only released as chat in Azure OpenAI\n",
    "\n",
    "# list models deployed with\n",
    "deployment_id = None\n",
    "result = openai.Deployment.list()\n",
    "\n",
    "for deployment in result.data:\n",
    "    if deployment[\"status\"] != \"succeeded\":\n",
    "        continue\n",
    "    \n",
    "    model = openai.Model.retrieve(deployment[\"model\"])\n",
    "    print(model)\n",
    "    # check if desired_model is deployed, and if it has 'completion' capability\n",
    "    if model[\"id\"] == desired_model and model['capabilities'][desired_capability]:\n",
    "        deployment_id = deployment[\"id\"]\n",
    "        \n",
    "# if no model deployed, deploy one\n",
    "if not deployment_id:\n",
    "    print('No deployment with status: succeeded found.')\n",
    "\n",
    "    # Deploy the model\n",
    "    print(f'Creating a new deployment with model: {desired_model}')\n",
    "    result = openai.Deployment.create(model=desired_model, scale_settings={\"scale_type\":\"standard\"})\n",
    "    deployment_id = result[\"id\"]\n",
    "    print(f'Successfully created {desired_model} that supports text {desired_capability} with id: {deployment_id}.')\n",
    "else:\n",
    "    print(f'Found a succeeded deployment of \"{desired_model}\" that supports text {desired_capability} with id: {deployment_id}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ? How to deal with long document ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
